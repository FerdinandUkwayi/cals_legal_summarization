Context-Aware Legal Summarizer (CALS) Prototype

Executive Summary

The Context-Aware Legal Summarizer (CALS) v10 is a research prototype developed to empirically test the feasibility of building dynamically adaptive NLP systems for the high-stakes legal domain.

Primary Goal: To investigate whether explicitly embedding user-defined adversarial context (e.g., Plaintiff vs. Defendant) into the summarization pipeline can produce demonstrably more relevant and higher-utility summaries than generalized models.

Core Finding: The final adversarial test revealed that standard Sequence-to-Sequence fine-tuning, even with aggressive data augmentation, failed to achieve semantic divergence between opposing goals. This finding serves as a critical empirical contribution, defining the methodological limitations of current NLP techniques when applied to adversarial legal subjectivity.


ğŸ”§ Technologies & Libraries Used:
- Python 3.10+
- Streamlit
- Hugging Face Transformers
- Hugging Face Datasets
- SQLite
- Pandas
- scikit-learn
- Matplotlib / Altair (for dashboard)
- bcrypt (for password hashing)

Model Details:
--------------------------------------------------------
1. Pretrained Model: facebook/bart-large-cnn
2. Fine-Tuned Version: Trained on a legal dataset using Hugging Face's Trainer API in Google Colab
3. Evaluation: ROUGE metrics (ROUGE-1, ROUGE-2, ROUGE-L)

--------------------------------------------------------
ğŸ“ Folder Structure:
--------------------------------------------------------

legal_summarizer/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ assets/               â†’ UI backgrounds, images
â”‚   â”œâ”€â”€ models/               â†’ fine-tuned model (finetuned_bart/)
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ 1_home.py         â†’ Welcome page
â”‚   â”‚   â”œâ”€â”€ 2_summarizer.py   â†’ Upload and summarize documents
â”‚   â”‚   â””â”€â”€ 3_dashboard.py    â†’ Visual analytics dashboard
â”‚   â”œâ”€â”€ backend.py            â†’ Summarization logic & pipeline
â”‚   â”œâ”€â”€ db.py                 â†’ Summary database logic (SQLite)
â”‚   â”œâ”€â”€ users.py              â†’ User authentication module
â”‚   â”œâ”€â”€ utils.py              â†’ Evaluation and helper functions
â”‚   â””â”€â”€ login_page.py         â†’ Main app entry, Login/Register page
â”‚
â”œâ”€â”€ database/                 â†’ Stores app.db (SQLite)
â”œâ”€â”€ requirements.txt          â†’ All dependencies
â”œâ”€â”€ README.txt                â†’ This file
â””â”€â”€ finetuning_notebook.ipynb â†’ Colab notebook for fine-tuning

--------------------------------------------------------
ğŸš€ Features:
--------------------------------------------------------

âœ… Upload and summarize PDF or text content  
âœ… Chunking support for long legal texts  
âœ… Option to use pretrained or fine-tuned model  
âœ… ROUGE metric evaluation  
âœ… SQLite-based history tracking  
âœ… Dashboard with visual analytics (date, method, length, file)  
âœ… Login/Register system with hashed passwords  
âœ… Clean and professional UI  
âœ… Easily deployable (local or cloud)

--------------------------------------------------------
ğŸ§ª Model Fine-Tuning (Colab Overview):
--------------------------------------------------------

Fine-tuned using Hugging Face's facebook/bart-large-cnn model on a custom legal dataset in Colab.  
Steps:
- Load & preprocess dataset (text, summary)
- Tokenize and train using Trainer API
- Save model and integrate into the Streamlit app

ğŸ“Œ Training parameters:
- Epochs: 2  
- Batch size: 2  
- Max length: 1024 tokens  
- Output: app/models/finetuned_bart/

--------------------------------------------------------
ğŸ“¦ Setup & Usage:
--------------------------------------------------------

1. Clone or extract the project
2. Create a virtual environment:
   python -m venv .venv
   .venv\Scripts\activate  (Windows)
3. Install dependencies:
   pip install -r requirements.txt
4. Run the app:
   streamlit run app/login_page.py

--------------------------------------------------------
ğŸ“Œ Additional Notes:
--------------------------------------------------------

- Users must register and log in to use the app
- Summaries are saved to the database with metadata
- Dashboard charts provide insights into usage
- Code is modular, clean, and fully commented


